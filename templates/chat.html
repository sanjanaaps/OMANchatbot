{% extends "base.html" %}

{% block title %}AI Assistant Chat{% endblock %}

{% block content %}
<div class="px-4 py-6 sm:px-0">
    <div class="max-w-4xl mx-auto">
        <!-- Header -->
        <div class="mb-8">
            <h1 class="text-3xl font-bold text-gray-900">
                <i class="fas fa-comments text-ocb-blue mr-3"></i>
                AI Assistant Chat
            </h1>
            <p class="mt-2 text-gray-600">
                Chat with the AI assistant about your department's documents. The assistant can only access information from your department.
            </p>
        </div>

        <!-- Chat Interface -->
        <div class="bg-white shadow sm:rounded-lg">
            <div class="px-4 py-5 sm:p-6">
                <!-- Chat Messages -->
                <div id="chatMessages" class="space-y-4 mb-6 max-h-96 overflow-y-auto border border-gray-200 rounded-lg p-4">
                    {% if messages %}
                        {% for message in messages %}
                        <div class="flex {% if message.type == 'user' %}justify-end{% else %}justify-start{% endif %}">
                            <div class="max-w-xs lg:max-w-md px-4 py-2 rounded-lg {% if message.type == 'user' %}bg-ocb-blue text-white{% else %}bg-gray-100 text-gray-800{% endif %}">
                                {% if message.type == 'assistant' %}
                                <div class="flex items-center mb-1">
                                    <i class="fas fa-robot text-ocb-blue mr-2"></i>
                                    <span class="text-xs font-medium">AI Assistant</span>
                                </div>
                                {% endif %}
                                <p class="text-sm">{{ message.content|safe }}</p>
                            </div>
                        </div>
                        {% endfor %}
                    {% else %}
                    <div class="text-center text-gray-500 py-8">
                        <i class="fas fa-comments text-4xl mb-4"></i>
                        <p>Start a conversation with the AI assistant</p>
                        <p class="text-sm mt-2">Ask questions about your department's documents</p>
                    </div>
                    {% endif %}
                </div>

                <!-- Chat Input Form -->
                <form method="POST" class="space-y-4">
                    <!-- Audio Recording -->
                    <div class="border border-gray-200 rounded-lg p-4">
                        <div class="flex items-center justify-between mb-3">
                            <div class="flex items-center space-x-2">
                                <!-- Fixed initial button styling -->
                                <button type="button" id="recordBtn" onclick="toggleRecording()" 
                                        class="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-red-600 hover:bg-red-700 transition-colors duration-200">
                                    <i class="fas fa-microphone mr-2" id="recordIcon"></i>
                                    <span id="recordBtnLabel">Start Recording</span>
                                </button>
                                <span id="recordTimer" class="text-sm text-gray-600 font-mono">00:00 / 01:00</span>
                                <div id="recordingStatus" class="text-xs text-gray-500"></div>
                            </div>
                            <div class="text-xs text-gray-500">Max 1 minute</div>
                        </div>
                        <div class="mb-3">
                            <!-- Fixed canvas with proper sizing -->
                            <canvas id="waveformCanvas" width="600" height="64" 
                                    class="w-full bg-gray-50 border border-gray-200 rounded" 
                                    style="height: 64px;"></canvas>
                        </div>
                        <div>
                            <label for="liveTranscript" class="block text-sm font-medium text-gray-700 mb-1">Live Transcription</label>
                            <textarea id="liveTranscript" rows="2" 
                                      class="shadow-sm focus:ring-ocb-blue focus:border-ocb-blue block w-full sm:text-sm border-gray-300 rounded-md" 
                                      placeholder="Transcribed words will appear here in real time..." readonly></textarea>
                        </div>
                    </div>
                    <div class="flex items-center space-x-4">
                        <div class="flex-1">
                            <label for="message" class="sr-only">Message</label>
                            <textarea name="message" id="message" rows="2" 
                                      class="shadow-sm focus:ring-ocb-blue focus:border-ocb-blue block w-full sm:text-sm border-gray-300 rounded-md"
                                      placeholder="Ask a question about your department's documents or use the microphone above..."
                                      required></textarea>
                        </div>
                        <div class="flex flex-col space-y-2">
                            <select name="language" id="language" class="block w-32 pl-3 pr-10 py-2 text-base border-gray-300 focus:outline-none focus:ring-ocb-blue focus:border-ocb-blue sm:text-sm rounded-md">
                                <option value="en">English</option>
                                <option value="ar">العربية</option>
                            </select>
                            <button type="submit" class="inline-flex items-center px-4 py-2 border border-transparent text-sm font-medium rounded-md text-white bg-ocb-blue hover:bg-blue-700 transition-colors duration-200">
                                <i class="fas fa-paper-plane mr-2"></i>
                                Send
                            </button>
                        </div>
                    </div>
                </form>
            </div>
        </div>
    </div>
</div>
{% endblock %}

{% block scripts %}
<script>
(function() {
    'use strict';
    
    // Elements
    const recordBtn = document.getElementById('recordBtn');
    const recordBtnLabel = document.getElementById('recordBtnLabel');
    const recordIcon = document.getElementById('recordIcon');
    const recordTimer = document.getElementById('recordTimer');
    const recordingStatus = document.getElementById('recordingStatus');
    const canvas = document.getElementById('waveformCanvas');
    const transcriptEl = document.getElementById('liveTranscript');
    const messageTextarea = document.getElementById('message');

    if (!recordBtn || !recordTimer || !canvas || !transcriptEl) {
        console.error('Required elements not found');
        return;
    }

    const canvasCtx = canvas.getContext('2d');
    let isRecording = false;
    let startTime = 0;
    let timerInterval = null;
    let rafId = null;

    // Media
    let mediaStream = null;
    let mediaRecorder = null;
    let audioContext = null;
    let analyser = null;
    let source = null;
    let dataArray = null;
    let bufferLength = 0;

    // Server session
    let voiceSessionId = null;
    let recordedChunks = [];
    let transcriptPollInterval = null;

    function formatTime(ms) {
        const totalSec = Math.min(60, Math.floor(ms / 1000));
        const mm = String(Math.floor(totalSec / 60)).padStart(2, '0');
        const ss = String(totalSec % 60).padStart(2, '0');
        return `${mm}:${ss} / 01:00`;
    }

    function clearCanvas() {
        if (!canvasCtx) return;
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
        canvasCtx.fillStyle = '#f9fafb';
        canvasCtx.fillRect(0, 0, canvas.width, canvas.height);
    }

    function resizeCanvas() {
        const rect = canvas.getBoundingClientRect();
        const dpr = window.devicePixelRatio || 1;
        
        // Set actual canvas size
        canvas.width = Math.max(600, rect.width * dpr);
        canvas.height = 64 * dpr;
        
        // Scale the drawing context
        canvasCtx.scale(dpr, dpr);
        
        // Set display size
        canvas.style.width = rect.width + 'px';
        canvas.style.height = '64px';
        
        clearCanvas();
    }

    function drawWaveform() {
        if (!analyser || !dataArray || !isRecording) return;
        
        try {
            analyser.getByteTimeDomainData(dataArray);

            // Clear canvas
            canvasCtx.fillStyle = '#f9fafb';
            canvasCtx.fillRect(0, 0, canvas.width / (window.devicePixelRatio || 1), canvas.height / (window.devicePixelRatio || 1));

            // Draw waveform
            canvasCtx.lineWidth = 2;
            canvasCtx.strokeStyle = '#1e40af';
            canvasCtx.beginPath();

            const sliceWidth = (canvas.width / (window.devicePixelRatio || 1)) / bufferLength;
            let x = 0;

            for (let i = 0; i < bufferLength; i++) {
                const v = dataArray[i] / 128.0;
                const y = (v * (canvas.height / (window.devicePixelRatio || 1))) / 2;

                if (i === 0) {
                    canvasCtx.moveTo(x, y);
                } else {
                    canvasCtx.lineTo(x, y);
                }

                x += sliceWidth;
            }

            canvasCtx.lineTo(canvas.width / (window.devicePixelRatio || 1), (canvas.height / (window.devicePixelRatio || 1)) / 2);
            canvasCtx.stroke();

            rafId = requestAnimationFrame(drawWaveform);
        } catch (error) {
            console.error('Waveform drawing error:', error);
        }
    }

    function updateButtonState(recording) {
        if (recording) {
            recordBtn.classList.remove('bg-red-600', 'hover:bg-red-700');
            recordBtn.classList.add('bg-gray-600', 'hover:bg-gray-700');
            recordBtnLabel.textContent = 'Stop Recording';
            recordIcon.classList.remove('fa-microphone');
            recordIcon.classList.add('fa-stop');
            recordingStatus.textContent = 'Recording...';
            recordingStatus.classList.add('text-red-600');
        } else {
            recordBtn.classList.remove('bg-gray-600', 'hover:bg-gray-700');
            recordBtn.classList.add('bg-red-600', 'hover:bg-red-700');
            recordBtnLabel.textContent = 'Start Recording';
            recordIcon.classList.remove('fa-stop');
            recordIcon.classList.add('fa-microphone');
            recordingStatus.textContent = '';
            recordingStatus.classList.remove('text-red-600');
        }
    }

    async function startRecording() {
        try {
            recordBtn.disabled = true;
            recordingStatus.textContent = 'Starting...';
            
            // Check browser support
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                throw new Error('Microphone access not supported by this browser');
            }

            // Start server voice session (if available)
            try {
                const res = await fetch('/voice/start', { method: 'POST' });
                if (res.ok) {
                    const data = await res.json();
                    voiceSessionId = data.session_id;
                }
            } catch (error) {
                console.log('Voice session not available, recording locally only');
            }

            // Get microphone access
            mediaStream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });

            // Create audio context for visualization
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            
            if (audioContext.state === 'suspended') {
                await audioContext.resume();
            }

            analyser = audioContext.createAnalyser();
            source = audioContext.createMediaStreamSource(mediaStream);
            source.connect(analyser);
            
            analyser.fftSize = 2048;
            bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);

            // Setup media recorder
            const options = {};
            if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                options.mimeType = 'audio/webm;codecs=opus';
            } else if (MediaRecorder.isTypeSupported('audio/webm')) {
                options.mimeType = 'audio/webm';
            }

            mediaRecorder = new MediaRecorder(mediaStream, options);
            recordedChunks = [];

            mediaRecorder.ondataavailable = async (event) => {
                if (event.data && event.data.size > 0) {
                    recordedChunks.push(event.data);
                    
                    // Send to server if session available
                    if (voiceSessionId) {
                        try {
                            const formData = new FormData();
                            formData.append('session_id', voiceSessionId);
                            formData.append('sample_rate_hz', String(audioContext.sampleRate));
                            formData.append('audio', event.data, 'chunk.webm');
                            await fetch('/voice/chunk', { method: 'POST', body: formData });
                        } catch (error) {
                            console.error('Failed to send audio chunk:', error);
                        }
                    }
                }
            };

            mediaRecorder.start(250); // Record in 250ms chunks

            // Start recording state
            isRecording = true;
            startTime = Date.now();
            updateButtonState(true);
            
            transcriptEl.value = '';
            resizeCanvas();
            drawWaveform();

            // Start timer
            timerInterval = setInterval(async () => {
                const elapsed = Date.now() - startTime;
                recordTimer.textContent = formatTime(elapsed);
                
                if (elapsed >= 60000) {
                    await stopRecording();
                }
            }, 100);

            // Start transcript polling if server session exists
            if (voiceSessionId) {
                transcriptPollInterval = setInterval(async () => {
                    try {
                        const res = await fetch(`/voice/transcript?session_id=${encodeURIComponent(voiceSessionId)}`);
                        if (res.ok) {
                            const data = await res.json();
                            if (data.transcript) {
                                transcriptEl.value = data.transcript;
                            }
                        }
                    } catch (e) {
                        // ignore polling errors
                    }
                }, 1000);
            }

            recordBtn.disabled = false;

        } catch (error) {
            console.error('Failed to start recording:', error);
            recordingStatus.textContent = `Error: ${error.message}`;
            recordingStatus.classList.add('text-red-600');
            
            // Cleanup on error
            await cleanup();
            recordBtn.disabled = false;
        }
    }

    async function stopRecording() {
        if (!isRecording) return;
        
        isRecording = false;
        updateButtonState(false);
        recordingStatus.textContent = 'Processing...';

        try {
            // Stop media recorder
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                await new Promise((resolve) => {
                    mediaRecorder.onstop = resolve;
                    mediaRecorder.stop();
                });
            }

            await cleanup();

            // Get final transcript from server
            if (voiceSessionId) {
                try {
                    const response = await fetch('/voice/finalize', {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({ session_id: voiceSessionId })
                    });
                    
                    if (response.ok) {
                        const result = await response.json();
                        if (result.transcript) {
                            transcriptEl.value = result.transcript;
                            // Also populate the message textarea
                            messageTextarea.value = result.transcript;
                        }
                    }
                } catch (error) {
                    console.error('Failed to get transcript:', error);
                }
                voiceSessionId = null;
            } else {
                // Fallback: show that recording was captured
                transcriptEl.value = 'Recording completed (server transcription not available)';
            }

            recordingStatus.textContent = 'Complete';
            setTimeout(() => {
                recordingStatus.textContent = '';
            }, 2000);

        } catch (error) {
            console.error('Error stopping recording:', error);
            recordingStatus.textContent = 'Error stopping recording';
        }
    }

    async function cleanup() {
        // Stop animation
        if (rafId) {
            cancelAnimationFrame(rafId);
            rafId = null;
        }

        // Clear timer
        if (timerInterval) {
            clearInterval(timerInterval);
            timerInterval = null;
        }

        // Clear transcript polling
        if (transcriptPollInterval) {
            clearInterval(transcriptPollInterval);
            transcriptPollInterval = null;
        }

        // Close media stream
        if (mediaStream) {
            mediaStream.getTracks().forEach(track => track.stop());
            mediaStream = null;
        }

        // Close audio context
        if (audioContext && audioContext.state !== 'closed') {
            try {
                await audioContext.close();
            } catch (error) {
                console.error('Error closing audio context:', error);
            }
            audioContext = null;
        }

        // Reset UI
        recordTimer.textContent = '00:00 / 01:00';
        clearCanvas();
        
        // Clean up references
        analyser = null;
        source = null;
        dataArray = null;
        mediaRecorder = null;
    }

    // Global function for button click
    window.toggleRecording = async function() {
        if (isRecording) {
            await stopRecording();
        } else {
            await startRecording();
        }
    };

    // Initialize
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();
    
    // Test canvas drawing on load
    setTimeout(() => {
        clearCanvas();
        // Draw a test line to verify canvas is working
        canvasCtx.strokeStyle = '#e5e7eb';
        canvasCtx.lineWidth = 1;
        canvasCtx.beginPath();
        canvasCtx.moveTo(0, canvas.height / (window.devicePixelRatio || 1) / 2);
        canvasCtx.lineTo(canvas.width / (window.devicePixelRatio || 1), canvas.height / (window.devicePixelRatio || 1) / 2);
        canvasCtx.stroke();
    }, 100);

})();
</script>
{% endblock %}
